## Neural Networks
- Single Layer Perceptron (SLP)
- Multi Layer Perceptron (MLP)
## SLP architecture:
    - activation function: softmax
    - cost function: cross entropy
## MLP architecture:
    - 1st layer: sigmoid
    - 2nd layer: softmax
    - cost function: cross entropy
## Features:
    - Early stopping
    - Variable learning rate
    - Plot error vs iteration
## Backpropagation
The derivatives calculations are available at:  
https://github.com/vivamoto/Classifier/blob/master/Neural_Network_Derivatives.pdf
   
## Reference
Lecture notes of Prof Clodoaldo Lima
